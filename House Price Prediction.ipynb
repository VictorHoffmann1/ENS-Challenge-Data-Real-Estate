{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c8576d",
   "metadata": {},
   "source": [
    "# House Price Prediction with Images and Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5125e0",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e833b",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b087e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_test= pd.read_csv('./Challenge/Data/X_test.csv')\n",
    "X_train_raw = pd.read_csv('./Challenge/Data/X_train.csv')\n",
    "y_random_raw = pd.read_csv('./Challenge/Data/y_random.csv')\n",
    "y_train_raw = pd.read_csv('./Challenge/Data/y_train.csv')\n",
    "train = pd.merge(X_train_raw, y_train_raw, how = \"outer\", on = \"id_annonce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a1e81",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26183457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import skimage.measure \n",
    "path_train = './Challenge/Data/reduced_images_ILB/reduced_images/train'\n",
    "path_test = './Challenge/Data/reduced_images_ILB/reduced_images/test'\n",
    "test_annonce = np.array(X_test.id_annonce)\n",
    "train_annonce = np.array(train.id_annonce)\n",
    "\n",
    "#TRAIN IMAGES\n",
    "\n",
    "dict = {'id_annonce':[]}\n",
    "dict['Entropy'] = [] # Calculating the image's entropy and inserting it in the table.\n",
    "image_features = []\n",
    "for annonce in train_annonce:\n",
    "    path = path_train+f'/ann_{annonce}'\n",
    "    images_path = os.listdir(path)\n",
    "    entropy = []\n",
    "    output_image = np.zeros((140,210), dtype = np.int8)\n",
    "    count = 0\n",
    "    for i in images_path:\n",
    "        m = count//3\n",
    "        n = count%3\n",
    "        img0 = Image.open(path+f'/{i}')\n",
    "        img = img0.convert('L')\n",
    "        imagea = np.asarray(img, dtype='uint8')\n",
    "        image = cv2.resize(imagea, (70,70)).tolist()\n",
    "        entropy.append(skimage.measure.shannon_entropy(image))\n",
    "         # As each house has between 1 and 6 images, I put each images in a 210*140 image \n",
    "        output_image[m*70:(m+1)*70,n*70:(n+1)*70] = image\n",
    "        count += 1\n",
    "    image_features.append(output_image)\n",
    "    dict['Entropy'].append(np.mean(entropy))\n",
    "    dict['id_annonce'].append(annonce)\n",
    "\n",
    "dict['Image'] = image_features\n",
    "train_images = pd.DataFrame(data=dict)\n",
    "\n",
    "#TEST IMAGES\n",
    "\n",
    "dict = {'id_annonce':[]}\n",
    "dict['Entropy'] = []\n",
    "image_features =[]\n",
    "for annonce in test_annonce:\n",
    "    path = path_test+f'/ann_{annonce}'\n",
    "    images_path = os.listdir(path)\n",
    "    entropy = []\n",
    "    output_image = np.zeros((140,210), dtype = np.int8)\n",
    "    count = 0\n",
    "    for i in images_path:\n",
    "        m = count//3\n",
    "        n = count%3\n",
    "        img0 = Image.open(path+f'/{i}')\n",
    "        img = img0.convert('L')\n",
    "        imagea = np.asarray(img, dtype='uint8')\n",
    "        image = cv2.resize(imagea, (70,70)).tolist()\n",
    "        entropy.append(skimage.measure.shannon_entropy(image))\n",
    "        output_image[m*70:(m+1)*70,n*70:(n+1)*70] = image\n",
    "        count += 1\n",
    "    image_features.append(output_image)\n",
    "    dict['Entropy'].append(np.mean(entropy))\n",
    "    dict['id_annonce'].append(annonce)\n",
    "\n",
    "dict['Image'] = image_features\n",
    "test_images = pd.DataFrame(data=dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b75e0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac1b1df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    }
   ],
   "source": [
    "train.pop('city')\n",
    "X_test.pop('city')\n",
    "\n",
    "columns_str = np.array(['id_annonce','property_type','energy_performance_category','ghg_category','exposition','postal_code'])\n",
    "columns_train = np.array(train.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to impute most occured category and add importance vairable\n",
    "def impute_nan_add_vairable(DataFrame,ColName):\n",
    "    #1. add new column and replace if category is null then 1 else 0\n",
    "    DataFrame[ColName+\"_Imputed\"] =   np.where(DataFrame[ColName].isnull(),1,0)\n",
    "    \n",
    "    # 2. Take most occured category in that vairable (.mode())\n",
    "    \n",
    "    Mode_Category = DataFrame[ColName].mode()[0]\n",
    "    \n",
    "    ## 2.1 Replace NAN values with most occured category in actual vairable\n",
    "    \n",
    "    DataFrame[ColName].fillna(Mode_Category,inplace=True)\n",
    "# Call function to impute NAN values and add new importance feature\n",
    "\n",
    "for i in columns_train:\n",
    "    if i in columns_str:\n",
    "        impute_nan_add_vairable(train,i)\n",
    "    else:\n",
    "        median = np.nanmedian(np.array(train[[i]]).flatten())\n",
    "        train[[i]] = train[[i]].fillna(median)\n",
    "        \n",
    "columns_X_test = np.array(X_test.columns)\n",
    "for i in columns_X_test:\n",
    "    if i in columns_str:\n",
    "        impute_nan_add_vairable(X_test,i)\n",
    "    else:\n",
    "        median = np.nanmedian(np.array(X_test[[i]]).flatten())\n",
    "        X_test[[i]] = X_test[[i]].fillna(median)\n",
    "        \n",
    "        \n",
    "#TARGET ENCODING CATEGORICAL VALUES\n",
    "        \n",
    "from category_encoders import TargetEncoder\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "        \n",
    "for i in columns_str:\n",
    "    train[[f'{i}']] = encoder.fit_transform(train[f'{i}'], train['price'])\n",
    "    X_test[[f'{i}']] = encoder.transform(X_test[f'{i}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e319a9",
   "metadata": {},
   "source": [
    "## Creating a train and a test ensemble for tabular data and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae58657e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Complete_train = pd.merge(train, train_images, how = \"outer\", on = \"id_annonce\")\n",
    "Complete_test = pd.merge(X_test, test_images, how = \"outer\", on = \"id_annonce\")\n",
    "\n",
    "\n",
    "image_data = Complete_train.pop('Image')\n",
    "image_data_test = Complete_test.pop('Image')\n",
    "Complete_train.pop('id_annonce')\n",
    "Complete_test.pop('id_annonce')\n",
    "y_train = Complete_train.pop('price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e1a87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.array(image_data)\n",
    "image_data = image_data.tolist()\n",
    "image_data = np.asarray(image_data, dtype=np.int8)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a1f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_test = np.array(image_data_test)\n",
    "image_data_test = image_data_test.tolist()\n",
    "image_data_test = np.asarray(image_data_test)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8f949",
   "metadata": {},
   "source": [
    "# Concatenation of a CNN and a MLP with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6dfb3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b6c0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing tabular data.\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(Complete_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9093b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33becedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(regress=False):\n",
    "    # define our MLP network\n",
    "    model = Sequential(normalizer)\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "    # return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f4c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "    # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d49bc947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "# create the MLP and CNN models\n",
    "mlp = create_mlp(regress=False)\n",
    "cnn = create_cnn(70,70, 1, regress=False)\n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(1e-3)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(\n",
    "    x=[Complete_train, image_data], y=y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=500, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634ed37",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "786137b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [price]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "019a2ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 12s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([Complete_test, image_data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f11cf3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_annonce</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35160615</td>\n",
       "      <td>1.792943e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35830639</td>\n",
       "      <td>1.019728e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36016657</td>\n",
       "      <td>2.517493e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35759225</td>\n",
       "      <td>9.008312e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35252229</td>\n",
       "      <td>3.012731e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>36052217</td>\n",
       "      <td>6.182704e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9335</th>\n",
       "      <td>35823719</td>\n",
       "      <td>3.572681e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9336</th>\n",
       "      <td>35793053</td>\n",
       "      <td>2.975501e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337</th>\n",
       "      <td>36049283</td>\n",
       "      <td>5.380710e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>35853753</td>\n",
       "      <td>2.351801e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_annonce         price\n",
       "0       35160615  1.792943e+05\n",
       "1       35830639  1.019728e+06\n",
       "2       36016657  2.517493e+05\n",
       "3       35759225  9.008312e+04\n",
       "4       35252229  3.012731e+05\n",
       "...          ...           ...\n",
       "9334    36052217  6.182704e+05\n",
       "9335    35823719  3.572681e+05\n",
       "9336    35793053  2.975501e+05\n",
       "9337    36049283  5.380710e+05\n",
       "9338    35853753  2.351801e+05\n",
       "\n",
       "[9339 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[['price']] = y_pred.reshape(len(y_pred),1)\n",
    "submission = X_test[['id_annonce','price']]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07409623",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Submission.csv',header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
